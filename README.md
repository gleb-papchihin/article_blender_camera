

# Собираем генератор данных на Blender. Часть 2: Камера.


Всем привет! В предыдущей статье мы рассмотрели работу с объектами. Но для того, чтобы создать минимально жизнеспособный генератор, нужно разобраться в том, как работают камеры.

Содержание:

- Часть 1: Объекты. В этом блоке научимся взаимодействовать с объектами. Разберем получение доступа через API, перемещение, масштабирование и вращение
- Часть 2: Камера. Разберемся, как автоматически настроить фокусное расстояние, навести камеру на предмет и отобразить координаты объекта на кадр
- Часть 3: Материалы и освещение. Рассмотрим свойства источников света и работу с материалами через пользовательские свойства и драйверы
- Часть 4: Сборка проекта и рендеринг. Научимся загружать объекты из разных файлов и запускать рендеринг сцены через консоль


## Получение доступа к камере

На сцене камера отображается, как обычный объект (bpy.types.Object). Мы можем перемещать её по сцене и использовать свойства, которые рассмотрели в предыдущей статье. Однако у камеры есть набор специальных свойств (Например, фокусное расстояние. Об этом мы поговорим чуть позже), к которым можно получить доступ через экземпляр класса «bpy.types.Camera».

``` python
camera = bpy.data.objects['Camera']
type(camera)

camera_extra = camera.data # Этот экземпляр предоставляет доступ к специальным свойствам
type(camera_extra)
```

Также доступ к экземпляру «bpy.types.Camera» можно получить через «bpy.data.cameras».

``` python
camera_extra = bpy.data.cameras['Camera']
type(camera_extra)
```

На этом этапе, может показаться, что «bpy.data.cameras» и «bpy.data.objects» имеют одинаковые ключи. Но это не так.

*Изображение развёрнутой камеры (Объект + начинка)* 

Мы видим, что внутри объекта «Camera» находится экземпляр «bpy.types.Camera» с названием «Camera». Для наглядности, поменяем название камеры на «MyCamera».

``` python
camera_extra.name = 'MyCamera'
```

Теперь мы можем использовать это имя, как ключ в «bpy.data.cameras».


## Выбор основной камеры

Для настройки камеры, полезно понять какие объекты попадают в её поле зрения. Для этого мы можем переключиться в режем «Camera view», которой покажет, что видит основная камера сцены.

*Изображение кнопки / как выглядит режим*

Так как на сцене может быть несколько камер, нам нужно выбрать одну, с которой будет вестись съёмка.

``` python
scene = bpy.context.scene # Получаем сцену, с которой работаем
camera = bpy.data.objects['Camera'] # Получаем камеру, которую будем использовать
scene.camera = camera # Устанавливаем камеру, как основную для этой сцены
```

## Разрешение

Изменение разрешения камеры происходит не через её свойства, а через настройки рендеринга.

``` python
render = bpy.context.scene.render
render.resolution_x = 1920
render.resolution_y = 1080
```

Заметим, что эти настройки распространяются на все камеры.

*Гифка с несколькими камерами, разрешение которых меняется*


## Свойства камеры

На данный момент мы научились получать доступ к камере и менять разрешение съёмки. Пришло время разобраться со свойствами, которые предоставляет класс «bpy.types.Camera».


### lens

Это свойство отвечает за фокусное расстояние. Единицей измерения является миллиметр.

``` python
camera = bpy.data.objects['Camera']
camera.lens = 10
```

*Изображение изменения фокусного расстояния*


### sensor_width & sensor_height

Помимо фокусного расстояния, мы можем взаимодействовать с размером сенсорной матрицы. Как и в случае с фокусным расстоянием, единицей измерения является миллиметр. Размер матрицы удобно использовать, когда у нас есть реальная камера, свойства которой мы хотим воспроизвести при генерации данных.

``` python
camera = bpy.data.objects['Camera']
camera.sensor_width = 32
```

*GIF: изменение размера сенсора*


### shift_x & shift_y

Смысл этих свойств легче всего объяснить с помощью наглядного примера.

*Гифка: изменение shift_x. Вид камеры*

В примере выше мы меняли shift_x и тем самым смещали объектив влево и вправво относительно направления камеры. Аналогичным образом работает shift_y, только смещение происходит вверх и вних.

Однако у этого свойства есть одна хитрость: единицы измерения расчитываются относительно наибольшей стороны кадра. Например, если разрешение 1920x1080, то shift_x = 1 сместит объектив вправо на 1920 пикселей. Аналогично, если мы установим shift_y = 1, то окажется, что мы переместили объектив вверх на 1920 пикселей. Лично для меня это было небольшим сюрпризом. Я ожидал, что shift_x высчитывается относительно resolution_x, а shift_y - относительно resolution_y. Ниже приведен пример правильного использования shift_x и shift_y.

``` python
resolution = (
    bpy.context.scene.render.resolution_x,
    bpy.context.scene.render.resolution_y
    )

camera.data.shift_x = shift_x_in_px / max(resolution)
camera.data.shift_y = shift_y_in_px / max(resolution)
```


## Проецирование точек на кадр

Зачастую, нам требуются не только сгенерированная картинка, но и координаты объектов, изображенных на ней. Чтобы отобразить точку на кадр, можно использовать функцию «world_to_camera_view», находящуюся в библиотеке «bpy_extras». Для наглядности, попробуем получить координаты центра куба на кадре.

``` python
from bpy_extras.object_utils import world_to_camera_view

cube = bpy.data.objects['Cube']
scene = bpy.context.scene
camera = bpy.data.objects['Camera']

world_to_camera_view(scene, camera, cube.location)
# Выводим результат
```

В результате использования «world_to_camera_view» мы получичли 3 значения: координата по оси х, координата по оси y, дистанция до объекта.

*Изображение: Система координат world_to_camera_view*

*Изображение: matplotlib рисуем точку*


## Наведение на объект

На этом этапе, мы хотим навести камеру на интересующий нас объект. Для решения этой задачи есть два решения (возможно и больше, но я нашел только два).

### constraints

В blender есть встроенная возможность "приказать" камере отслеживать какой-то объект. Это делается следующим образом.

```python
def track_to(
        camera: bpy.types.Object, 
        target: bpy.types.Object
        ):
    constraint = camera.constraints.new(type="TRACK_TO")
    constraint.target = target
```

*GIF: Двигаем объект. Камера продолжает следить за ним*

Есть и другие интересные ограничения, которые можно вешать на объекты. Подробнее об этом можно прочитать в [документации](https://docs.blender.org/manual/en/latest/animation/constraints/index.html).


### mathutils.vector

Суть этого подхода в том, что мы высчитываем угол, на который нужно повернуть камеру, чтобы она смотрела на объект, а затем производим поворот. Самое замечательное, что в mathutils.vector, есть метод «to_track_quat», позволяющий расчитать необходимый нам угол.

``` python
def point_camera_at(
        camera: bpy.types.Object,
        target: mathutils.Vector,
        track_axis: str = 'Z',
        up_axis: str = 'Y'
        ):
    vector = camera.location - target
    camera.rotation_euler = vector.to_track_quat(
        track_axis,
        up_axis
        ).to_euler()

camera = bpy.data.objects['Camera']
cube = bpy.data.objects['Cube']
point_camera_at(camera, cube.location)
```

Поворачивая камеру через api стоит обратить внимание на одну небольшую хитрость: после поворота нужно вручную обновить состояние сцены. Если это не сделать, то функция «world_to_camera_view» будет возвращать проекции относительно предыдущего положения камеры. 

```python
bpy.context.view_layer.update()
```


## The end :)

Вы работали с blender и хотите обсудить прочитанное? Или поделиться своим опытом и знаниями, чтобы сделать статью более полной и полезной для новичков? Жду вас в комментариях!
